{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with Vertex Reduction server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and test a training container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_IMAGE = 'tensorflow/tensorflow:2.5.0-gpu'\n",
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "CUDA_VERSION='cuda-11-2'\n",
    "#BASE_IMAGE = 'gcr.io/deeplearning-platform-release/base-cu110'\n",
    "MODEL_GARDEN_VERSION = '2.5.0'\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT_ID}/model_garden'\n",
    "TF_TEXT='2.5.0'\n",
    "\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "RUN pip install tf-models-official=={MODEL_GARDEN_VERSION} tensorflow-text=={TF_TEXT}\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"-c\", \"print('Hello')\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  505.9kB\n",
      "Step 1/6 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      " ---> 950969e5619c\n",
      "Step 2/6 : RUN pip install tf-models-official==2.5.0 tensorflow-text==2.5.0\n",
      " ---> Using cache\n",
      " ---> 691637649ce1\n",
      "Step 3/6 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> bf564ec3645d\n",
      "Step 4/6 : COPY trainer /trainer\n",
      " ---> 6474559b990c\n",
      "Step 5/6 : ENTRYPOINT [\"python\"]\n",
      " ---> Running in 7181f5c00a06\n",
      "Removing intermediate container 7181f5c00a06\n",
      " ---> b0382c91d062\n",
      "Step 6/6 : CMD [\"-c\", \"print('Hello')\"]\n",
      " ---> Running in eda8e45114b7\n",
      "Removing intermediate container eda8e45114b7\n",
      " ---> c43db23b2739\n",
      "Successfully built c43db23b2739\n",
      "Successfully tagged gcr.io/jk-mlops-dev/model_garden:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t {TRAIN_IMAGE} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the container to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/model_garden]\n",
      "\n",
      "\u001b[1B0acc7932: Preparing \n",
      "\u001b[1B29ea19d2: Preparing \n",
      "\u001b[1B464d3f17: Preparing \n",
      "\u001b[1Bdaea14d2: Preparing \n",
      "\u001b[1Bb28de254: Preparing \n",
      "\u001b[1B52e30556: Preparing \n",
      "\u001b[1Bfc085027: Preparing \n",
      "\u001b[1B7d90a58d: Preparing \n",
      "\u001b[1B285b3362: Preparing \n",
      "\u001b[1B0730cb59: Preparing \n",
      "\u001b[1B18de1f93: Preparing \n",
      "\u001b[1Bd1dfb5d0: Preparing \n",
      "\u001b[1B686f5924: Preparing \n",
      "\u001b[1B5de2196f: Preparing \n",
      "\u001b[1B383a0e80: Preparing \n",
      "\u001b[1Beaf882b2: Preparing \n",
      "\u001b[1B2519572d: Preparing \n",
      "\u001b[1Bfbfba824: Preparing \n",
      "\u001b[14B2e30556: Waiting g \n",
      "\u001b[1B2a1c8291: Preparing \n",
      "\u001b[15Bc085027: Waiting g \n",
      "\u001b[1Bb363f69f: Preparing \n",
      "\u001b[16Bd90a58d: Waiting g \n",
      "\u001b[16B85b3362: Waiting g \n",
      "\u001b[16B730cb59: Waiting g \n",
      "\u001b[1B01dbc7de: Preparing \n",
      "\u001b[17B8de1f93: Waiting g \n",
      "\u001b[17B1dfb5d0: Waiting g \n",
      "\u001b[1Bb9e63cdf: Preparing \n",
      "\u001b[1B49f5bf51: Preparing \n",
      "\u001b[19B86f5924: Waiting g \n",
      "\u001b[1B325cc380: Preparing \n",
      "\u001b[20Bde2196f: Waiting g \n",
      "\u001b[34Bacc7932: Pushed lready exists 8kB\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[23A\u001b[2K\u001b[18A\u001b[2K\u001b[12A\u001b[2K\u001b[8A\u001b[2K\u001b[3A\u001b[2K\u001b[34A\u001b[2Klatest: digest: sha256:4e1b8746b7664f07659533d37921446461751dfa3dd414e5cb005893ba09c30b size: 7461\n"
     ]
    }
   ],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Vertext Training jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_worker_pool_specs(\n",
    "    image_uri,\n",
    "    args,\n",
    "    cmd, \n",
    "    replica_count=1,\n",
    "    machine_type='n1-standard-4',\n",
    "    accelerator_count=0,\n",
    "    accelerator_type='ACCELERATOR_TYPE_UNSPECIFIED',\n",
    "    reduction_server_count=0,\n",
    "    reduction_server_machine_type='n1-standard-4',\n",
    "    reduction_server_image_uri='gcr.io/cloud-aiplatform-restricted/reductionserver'\n",
    "):\n",
    "\n",
    "    if accelerator_count > 0:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type,\n",
    "            'accelerator_type': accelerator_type,\n",
    "            'accelerator_count': accelerator_count,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type\n",
    "        }\n",
    "    \n",
    "    container_spec = {\n",
    "        'image_uri': image_uri,\n",
    "        'args': args,\n",
    "        'command': cmd,\n",
    "    }\n",
    "    \n",
    "    chief_spec = {\n",
    "        'replica_count': 1,\n",
    "        'machine_spec': machine_spec,\n",
    "        'container_spec': container_spec\n",
    "    }\n",
    "\n",
    "    worker_pool_specs = [chief_spec]\n",
    "    if replica_count > 1:\n",
    "        workers_spec = {\n",
    "            'replica_count': replica_count - 1,\n",
    "            'machine_spec': machine_spec,\n",
    "            'container_spec': container_spec\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "        \n",
    "    if reduction_server_count > 1:\n",
    "        workers_spec = {\n",
    "            'replica_count': reduction_server_count,\n",
    "            'machine_spec': {\n",
    "                'machine_type': reduction_server_machine_type,\n",
    "            },\n",
    "            'container_spec': {\n",
    "                image_uri: reduction_server_image_uri\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return worker_pool_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--experiment=bert/sentence_prediction',\n",
      "                              '--mode=train_and_eval',\n",
      "                              '--model_dir=gs://jk-vertex-demos/jobs/JOB_20210610_144019/model',\n",
      "                              '--config_file=trainer/glue_mnli_matched.yaml',\n",
      "                              '--tfhub_cache_dir=gs://jk-vertex-demos/jobs/tfhub-cache',\n",
      "                              '--params_override=task.train_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record,task.validation_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record,task.train_data.global_batch_size=32,task.validation_data.global_batch_size=32,task.hub_module_url=https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4,runtime.num_gpus=1,runtime.distribution_strategy=mirrored,runtime.all_reduce_alg=nccl,trainer.train_steps=1200,trainer.steps_per_loop=100,trainer.summary_interval=100,trainer.validation_interval=400,trainer.checkpoint_interval=200'],\n",
      "                     'command': ['python', 'trainer/train.py'],\n",
      "                     'image_uri': 'gcr.io/jk-mlops-dev/model_garden'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "MNLI_TRAIN_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "MNLI_VALID_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'\n",
    "BERT_HUB_URL = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "\n",
    "job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "output_dir = f'gs://jk-vertex-demos/jobs'\n",
    "model_dir = f'{output_dir}/{job_name}/model'\n",
    "tfhub_cache_dir = f'{output_dir}/tfhub-cache'\n",
    "config_file = 'trainer/glue_mnli_matched.yaml'\n",
    "mode = 'train_and_eval'\n",
    "experiment = 'bert/sentence_prediction'\n",
    "\n",
    "machine_type = 'n1-standard-8'\n",
    "accelerator_count = 1\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "\n",
    "train_steps = 1200\n",
    "steps_per_loop = 100\n",
    "summary_interval = 100\n",
    "validation_interval = 400\n",
    "checkpoint_interval = 200\n",
    "\n",
    "replica_count = 2\n",
    "global_batch_size = 32\n",
    "all_reduce_alg = 'nccl'\n",
    "#strategy = 'mirrored'\n",
    "strategy = 'multi_worker_mirrored'\n",
    "\n",
    "reduction_server_count=0\n",
    "\n",
    "\n",
    "\n",
    "params_override = [\n",
    "    'task.train_data.input_path=' + MNLI_TRAIN_SPLIT,\n",
    "    'task.validation_data.input_path=' + MNLI_VALID_SPLIT,\n",
    "    'task.train_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.validation_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.hub_module_url=' + BERT_HUB_URL,\n",
    "    'runtime.num_gpus=' + str(accelerator_count),\n",
    "    'runtime.distribution_strategy=' + strategy,\n",
    "    'runtime.all_reduce_alg=' + all_reduce_alg,\n",
    "    'trainer.train_steps=' + str(train_steps),\n",
    "    'trainer.steps_per_loop=' + str(steps_per_loop),\n",
    "    'trainer.summary_interval=' + str(summary_interval),\n",
    "    'trainer.validation_interval=' + str(validation_interval),\n",
    "    'trainer.checkpoint_interval=' + str(checkpoint_interval),\n",
    "]\n",
    "\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"trainer/train.py\"\n",
    "]\n",
    "args = [\n",
    "    '--experiment=' + experiment,\n",
    "    '--mode=' + mode,\n",
    "    '--model_dir=' + model_dir,\n",
    "    '--config_file=' + config_file,\n",
    "    '--tfhub_cache_dir=' + tfhub_cache_dir,\n",
    "    '--params_override=' + ','.join(params_override),\n",
    "]\n",
    "\n",
    "worker_pool_specs = prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=args,\n",
    "    cmd=cmd,\n",
    "    replica_count=replica_count,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    accelerator_type=accelerator_type\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(pp.pformat(worker_pool_specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-west1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-staging'\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-west1/customJobs/7943259027146801152\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-west1/customJobs/7943259027146801152')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west1/training/7943259027146801152?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "display_name = job_name\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=display_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/895222332033/locations/us-west1/customJobs/7943259027146801152'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/7943259027146801152 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the container image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNLI_TRAIN_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "MNLI_VALID_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'\n",
    "BERT_HUB_URL = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "\n",
    "num_gpus = 2 \n",
    "strategy = 'mirrored'\n",
    "#strategy = 'multi_worker_mirrored'\n",
    "\n",
    "params_override = [\n",
    "    'task.train_data.input_path=' + MNLI_TRAIN_SPLIT,\n",
    "    'task.validation_data.input_path=' + MNLI_VALID_SPLIT,\n",
    "    'task.hub_module_url=' + BERT_HUB_URL,\n",
    "    'runtime.num_gpus=' + str(num_gpus),\n",
    "    'runtime.distribution_strategy=' + strategy,\n",
    "]\n",
    "\n",
    "params = ','.join(params_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --gpus all {TRAIN_IMAGE} trainer/train.py \\\n",
    "--experiment=bert/sentence_prediction \\\n",
    "--mode=train_and_eval \\\n",
    "--model_dir={STAGING_BUCKET}/test \\\n",
    "--config_file=trainer/glue_mnli_matched.yaml \\\n",
    "--params_override={params}  \n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
