{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with Vertex Reduction server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and test a training container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_IMAGE = 'tensorflow/tensorflow:2.5.0-gpu'\n",
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "CUDA_VERSION='cuda-11-2'\n",
    "#BASE_IMAGE = 'gcr.io/deeplearning-platform-release/base-cu110'\n",
    "MODEL_GARDEN_VERSION = '2.5.0'\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT_ID}/model_garden'\n",
    "TF_TEXT='2.5.0'\n",
    "\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "RUN pip install tf-models-official=={MODEL_GARDEN_VERSION} tensorflow-text=={TF_TEXT}\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"-c\", \"print('Hello')\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  219.2MB\n",
      "Step 1/6 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      " ---> b963122c3c2c\n",
      "Step 2/6 : RUN pip install tf-models-official==2.5.0 tensorflow-text==2.5.0\n",
      " ---> Using cache\n",
      " ---> 98f4335c1985\n",
      "Step 3/6 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> d430eb747f7d\n",
      "Step 4/6 : COPY trainer /trainer\n",
      " ---> Using cache\n",
      " ---> a7de9907f2af\n",
      "Step 5/6 : ENTRYPOINT [\"python\"]\n",
      " ---> Using cache\n",
      " ---> b5a51ba2c422\n",
      "Step 6/6 : CMD [\"-c\", \"print('Hello')\"]\n",
      " ---> Using cache\n",
      " ---> fb31989ee777\n",
      "Successfully built fb31989ee777\n",
      "Successfully tagged gcr.io/jk-mlops-dev/model_garden:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t {TRAIN_IMAGE} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the container to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/model_garden]\n",
      "\n",
      "\u001b[1Bbc983b4f: Preparing \n",
      "\u001b[1B1a77e98b: Preparing \n",
      "\u001b[1B961a296c: Preparing \n",
      "\u001b[1B53abc6c2: Preparing \n",
      "\u001b[1B3723ef37: Preparing \n",
      "\u001b[1B0089a9c0: Preparing \n",
      "\u001b[1B3e41a2c0: Preparing \n",
      "\u001b[1B25162004: Preparing \n",
      "\u001b[1B99d982dd: Preparing \n",
      "\u001b[1B6603d114: Preparing \n",
      "\u001b[1Bc97a79f1: Preparing \n",
      "\u001b[1Be02b8502: Preparing \n",
      "\u001b[1Bd34a65ac: Preparing \n",
      "\u001b[1Bce22e436: Preparing \n",
      "\u001b[1B7e013d33: Preparing \n",
      "\u001b[1Baff4f6ee: Preparing \n",
      "\u001b[1Be4ccb381: Preparing \n",
      "\u001b[1B90ceec1e: Preparing \n",
      "\u001b[1B0ab30137: Preparing \n",
      "\u001b[1Bed8ae595: Preparing \n",
      "\u001b[1B855df562: Preparing \n",
      "\u001b[1Bdb3c5655: Preparing \n",
      "\u001b[1B0a9a6a11: Preparing \n",
      "\u001b[1B7e8b38e6: Preparing \n",
      "\u001b[1B8f196cf4: Preparing \n",
      "\u001b[1B01dbc7de: Preparing \n",
      "\u001b[1B31d2d72b: Preparing \n",
      "\u001b[21B5162004: Waiting g \n",
      "\u001b[1Bb9e63cdf: Preparing \n",
      "\u001b[22B9d982dd: Waiting g \n",
      "\u001b[1Baa2fa9fe: Preparing \n",
      "\u001b[1B325cc380: Preparing \n",
      "\u001b[24B603d114: Waiting g \n",
      "\u001b[34Bc983b4f: Pushed lready exists 8kB\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[25A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[26A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[34A\u001b[2Klatest: digest: sha256:b482dbaec7e08cc27c2dffe100543ba300e4811740daae7aef7903969d21cb22 size: 7461\n"
     ]
    }
   ],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Vertext Training jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_worker_pool_specs(\n",
    "    image_uri,\n",
    "    args,\n",
    "    cmd, \n",
    "    replica_count=1,\n",
    "    machine_type='n1-standard-4',\n",
    "    accelerator_count=0,\n",
    "    accelerator_type='ACCELERATOR_TYPE_UNSPECIFIED'):\n",
    "\n",
    "    if accelerator_count > 0:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type,\n",
    "            'accelerator_type': accelerator_type,\n",
    "            'accelerator_count': accelerator_count,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type\n",
    "        }\n",
    "    \n",
    "    container_spec = {\n",
    "        'image_uri': image_uri,\n",
    "        'args': args,\n",
    "        'command': cmd,\n",
    "    }\n",
    "    \n",
    "    chief_spec = {\n",
    "        'replica_count': 1,\n",
    "        'machine_spec': machine_spec,\n",
    "        'container_spec': container_spec\n",
    "    }\n",
    "\n",
    "    worker_pool_specs = [chief_spec]\n",
    "    if replica_count > 1:\n",
    "        workers_spec = {\n",
    "            'replica_count': replica_count - 1,\n",
    "            'machine_spec': machine_spec,\n",
    "            'container_spec': container_spec\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "    \n",
    "    return worker_pool_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--experiment=bert/sentence_prediction',\n",
      "                              '--mode=train_and_eval',\n",
      "                              '--model_dir=gs://jk-vertex-demos/jobs/JOB_20210529_185128/model',\n",
      "                              '--config_file=trainer/glue_mnli_matched.yaml',\n",
      "                              '--tfhub_cache_dir=gs://jk-vertex-demos/jobs/tfhub-cache',\n",
      "                              '--params_override=task.train_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record,task.validation_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record,task.train_data.global_batch_size=32,task.validation_data.global_batch_size=32,task.hub_module_url=https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4,runtime.num_gpus=1,runtime.distribution_strategy=mirrored,runtime.distribution_strategy=multi_worker_mirrored,runtime.all_reduce_alg=nccl,trainer.train_steps=1200,trainer.steps_per_loop=100,trainer.summary_interval=100,trainer.validation_interval=400,trainer.checkpoint_interval=200'],\n",
      "                     'command': ['python', 'trainer/train.py'],\n",
      "                     'image_uri': 'gcr.io/jk-mlops-dev/model_garden'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'args': ['--experiment=bert/sentence_prediction',\n",
      "                              '--mode=train_and_eval',\n",
      "                              '--model_dir=gs://jk-vertex-demos/jobs/JOB_20210529_185128/model',\n",
      "                              '--config_file=trainer/glue_mnli_matched.yaml',\n",
      "                              '--tfhub_cache_dir=gs://jk-vertex-demos/jobs/tfhub-cache',\n",
      "                              '--params_override=task.train_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record,task.validation_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record,task.train_data.global_batch_size=32,task.validation_data.global_batch_size=32,task.hub_module_url=https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4,runtime.num_gpus=1,runtime.distribution_strategy=mirrored,runtime.distribution_strategy=multi_worker_mirrored,runtime.all_reduce_alg=nccl,trainer.train_steps=1200,trainer.steps_per_loop=100,trainer.summary_interval=100,trainer.validation_interval=400,trainer.checkpoint_interval=200'],\n",
      "                     'command': ['python', 'trainer/train.py'],\n",
      "                     'image_uri': 'gcr.io/jk-mlops-dev/model_garden'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "MNLI_TRAIN_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "MNLI_VALID_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'\n",
    "BERT_HUB_URL = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "\n",
    "job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "output_dir = f'gs://jk-vertex-demos/jobs'\n",
    "model_dir = f'{output_dir}/{job_name}/model'\n",
    "tfhub_cache_dir = f'{output_dir}/tfhub-cache'\n",
    "config_file = 'trainer/glue_mnli_matched.yaml'\n",
    "mode = 'train_and_eval'\n",
    "experiment = 'bert/sentence_prediction'\n",
    "\n",
    "machine_type = 'n1-standard-8'\n",
    "accelerator_count = 1\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "strategy = 'mirrored'\n",
    "#strategy = 'multi_worker_mirrored'\n",
    "train_steps = 1200\n",
    "steps_per_loop = 100\n",
    "summary_interval = 100\n",
    "validation_interval = 400\n",
    "checkpoint_interval = 200\n",
    "\n",
    "replica_count = 2\n",
    "global_batch_size = 32\n",
    "\n",
    "params_override = [\n",
    "    'task.train_data.input_path=' + MNLI_TRAIN_SPLIT,\n",
    "    'task.validation_data.input_path=' + MNLI_VALID_SPLIT,\n",
    "    'task.train_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.validation_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.hub_module_url=' + BERT_HUB_URL,\n",
    "    'runtime.num_gpus=' + str(accelerator_count),\n",
    "    'runtime.distribution_strategy=' + strategy,\n",
    "    'runtime.distribution_strategy=multi_worker_mirrored',\n",
    "    'runtime.all_reduce_alg=' + 'nccl',\n",
    "    'trainer.train_steps=' + str(train_steps),\n",
    "    'trainer.steps_per_loop=' + str(steps_per_loop),\n",
    "    'trainer.summary_interval=' + str(summary_interval),\n",
    "    'trainer.validation_interval=' + str(validation_interval),\n",
    "    'trainer.checkpoint_interval=' + str(checkpoint_interval),\n",
    "]\n",
    "\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"trainer/train.py\"\n",
    "]\n",
    "args = [\n",
    "    '--experiment=' + experiment,\n",
    "    '--mode=' + mode,\n",
    "    '--model_dir=' + model_dir,\n",
    "    '--config_file=' + config_file,\n",
    "    '--tfhub_cache_dir=' + tfhub_cache_dir,\n",
    "    '--params_override=' + ','.join(params_override),\n",
    "]\n",
    "\n",
    "worker_pool_specs = prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=args,\n",
    "    cmd=cmd,\n",
    "    replica_count=replica_count,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    accelerator_type=accelerator_type\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(pp.pformat(worker_pool_specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-west1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-staging'\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-west1/customJobs/3967706456085495808\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-west1/customJobs/3967706456085495808')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-west1/training/3967706456085495808?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3519598293162131456 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-west1/customJobs/3967706456085495808 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "display_name = job_name\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=display_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the container image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNLI_TRAIN_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "MNLI_VALID_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'\n",
    "BERT_HUB_URL = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "\n",
    "num_gpus = 2 \n",
    "strategy = 'mirrored'\n",
    "#strategy = 'multi_worker_mirrored'\n",
    "\n",
    "params_override = [\n",
    "    'task.train_data.input_path=' + MNLI_TRAIN_SPLIT,\n",
    "    'task.validation_data.input_path=' + MNLI_VALID_SPLIT,\n",
    "    'task.hub_module_url=' + BERT_HUB_URL,\n",
    "    'runtime.num_gpus=' + str(num_gpus),\n",
    "    'runtime.distribution_strategy=' + strategy,\n",
    "]\n",
    "\n",
    "params = ','.join(params_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --gpus all {TRAIN_IMAGE} trainer/train.py \\\n",
    "--experiment=bert/sentence_prediction \\\n",
    "--mode=train_and_eval \\\n",
    "--model_dir={STAGING_BUCKET}/test \\\n",
    "--config_file=trainer/glue_mnli_matched.yaml \\\n",
    "--params_override={params}  \n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m70",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m70"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
