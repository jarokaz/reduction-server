{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with Vertex Reduction server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gin\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "from official.common import distribute_utils\n",
    "from official.common import registry_imports\n",
    "from official.common import flags as tfm_flags\n",
    "from official.core import task_factory\n",
    "from official.core import train_lib\n",
    "from official.core import train_utils\n",
    "from official.modeling import performance\n",
    "\n",
    "from official.nlp.bert import tokenization\n",
    "from official.nlp.data import classifier_data_lib\n",
    "from official.nlp.data import sentence_retrieval_lib\n",
    "from official.nlp.data import squad_lib as squad_lib_wp\n",
    "from official.nlp.data import squad_lib_sp\n",
    "from official.nlp.data import tagging_data_lib\n",
    "\n",
    "from official.core import base_task\n",
    "from official.core import base_trainer\n",
    "from official.core import config_definitions\n",
    "from official.core import exp_factory\n",
    "from official.modeling import hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "GCS_LOCATION = 'gs://jk-vertex-demos'\n",
    "BERT_DIR = 'gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-24_H-1024_A-16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mnli_tfrecords(output_gcs_location, vocab_file, mnli_type='matched', \n",
    "                            max_seq_length=128, do_lower_case=True):\n",
    "    \"\"\"Generates MNLI training and validation splits in the TFRecord format\n",
    "    compatible with TensorfFlow NLP Modelling Toolkit.\"\"\"\n",
    "\n",
    "    train_data_output_path = f'{output_gcs_location}/mnli_train.tf_record'\n",
    "    eval_data_output_path = f'{output_gcs_location}/mnli_valid.tf_record'\n",
    "    metadata_file_path = f'{output_gcs_location}/metadata.json'\n",
    "\n",
    "    tokenizer = tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "    processor_text_fn = tokenization.convert_to_unicode\n",
    "\n",
    "    if mnli_type == 'matched':\n",
    "        tfds_params = 'dataset=glue/mnli,text_key=hypothesis,text_b_key=premise,train_split=train,dev_split=validation_matched'\n",
    "    else: \n",
    "        tfds_params = 'dataset=glue/mnli,text_key=hypothesis,text_b_key=premise,train_split=train,dev_split=validation_mismatched'\n",
    "\n",
    "    processor = classifier_data_lib.TfdsProcessor(\n",
    "        tfds_params=tfds_params, process_text_fn=processor_text_fn)\n",
    "\n",
    "    metadata = classifier_data_lib.generate_tf_record_from_data_file(\n",
    "        processor,\n",
    "        None,\n",
    "        tokenizer,\n",
    "        train_data_output_path=train_data_output_path,\n",
    "        eval_data_output_path=eval_data_output_path,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "    with tf.io.gfile.GFile(metadata_file_path, \"w\") as writer:\n",
    "        writer.write(json.dumps(metadata, indent=4) + \"\\n\")\n",
    "\n",
    "    return train_data_output_path, eval_data_output_path, metadata_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = f'{BERT_DIR}/vocab.txt'\n",
    "output_location = f'{GCS_LOCATION}/datasets/MNLI'\n",
    "\n",
    "train_file, eval_file, metadata_file = generate_mnli_tfrecords(output_location, vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "eval_file = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/tmp/models/bert_mnli'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the default configuration for sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'bert/sentence_prediction'\n",
    "\n",
    "params = exp_factory.get_exp_config(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the default configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runtime': {'all_reduce_alg': None,\n",
      "             'batchnorm_spatial_persistent': False,\n",
      "             'dataset_num_private_threads': None,\n",
      "             'default_shard_dim': -1,\n",
      "             'distribution_strategy': 'mirrored',\n",
      "             'enable_xla': False,\n",
      "             'gpu_thread_mode': None,\n",
      "             'loss_scale': None,\n",
      "             'mixed_precision_dtype': None,\n",
      "             'num_cores_per_replica': 1,\n",
      "             'num_gpus': 0,\n",
      "             'num_packs': 1,\n",
      "             'per_gpu_thread_count': 0,\n",
      "             'run_eagerly': False,\n",
      "             'task_index': -1,\n",
      "             'tpu': None,\n",
      "             'tpu_enable_xla_dynamic_padder': None,\n",
      "             'worker_hosts': None},\n",
      " 'task': {'hub_module_url': '',\n",
      "          'init_checkpoint': '',\n",
      "          'init_cls_pooler': False,\n",
      "          'metric_type': 'accuracy',\n",
      "          'model': {'encoder': {'bert': {'attention_dropout_rate': 0.1,\n",
      "                                         'dropout_rate': 0.1,\n",
      "                                         'embedding_size': None,\n",
      "                                         'hidden_activation': 'gelu',\n",
      "                                         'hidden_size': 768,\n",
      "                                         'initializer_range': 0.02,\n",
      "                                         'intermediate_size': 3072,\n",
      "                                         'max_position_embeddings': 512,\n",
      "                                         'num_attention_heads': 12,\n",
      "                                         'num_layers': 12,\n",
      "                                         'output_range': None,\n",
      "                                         'return_all_encoder_outputs': False,\n",
      "                                         'type_vocab_size': 2,\n",
      "                                         'vocab_size': 30522},\n",
      "                                'type': 'bert'},\n",
      "                    'num_classes': 0,\n",
      "                    'use_encoder_pooler': False},\n",
      "          'train_data': {'block_length': 1,\n",
      "                         'cache': False,\n",
      "                         'cycle_length': None,\n",
      "                         'deterministic': None,\n",
      "                         'drop_remainder': True,\n",
      "                         'enable_tf_data_service': False,\n",
      "                         'global_batch_size': 32,\n",
      "                         'include_example_id': False,\n",
      "                         'input_path': '',\n",
      "                         'is_training': True,\n",
      "                         'label_type': 'int',\n",
      "                         'seed': None,\n",
      "                         'seq_length': 128,\n",
      "                         'sharding': True,\n",
      "                         'shuffle_buffer_size': 100,\n",
      "                         'tf_data_service_address': None,\n",
      "                         'tf_data_service_job_name': None,\n",
      "                         'tfds_as_supervised': False,\n",
      "                         'tfds_data_dir': '',\n",
      "                         'tfds_name': '',\n",
      "                         'tfds_skip_decoding_feature': '',\n",
      "                         'tfds_split': ''},\n",
      "          'validation_data': {'block_length': 1,\n",
      "                              'cache': False,\n",
      "                              'cycle_length': None,\n",
      "                              'deterministic': None,\n",
      "                              'drop_remainder': False,\n",
      "                              'enable_tf_data_service': False,\n",
      "                              'global_batch_size': 32,\n",
      "                              'include_example_id': False,\n",
      "                              'input_path': '',\n",
      "                              'is_training': False,\n",
      "                              'label_type': 'int',\n",
      "                              'seed': None,\n",
      "                              'seq_length': 128,\n",
      "                              'sharding': True,\n",
      "                              'shuffle_buffer_size': 100,\n",
      "                              'tf_data_service_address': None,\n",
      "                              'tf_data_service_job_name': None,\n",
      "                              'tfds_as_supervised': False,\n",
      "                              'tfds_data_dir': '',\n",
      "                              'tfds_name': '',\n",
      "                              'tfds_skip_decoding_feature': '',\n",
      "                              'tfds_split': ''}},\n",
      " 'trainer': {'allow_tpu_summary': False,\n",
      "             'best_checkpoint_eval_metric': '',\n",
      "             'best_checkpoint_export_subdir': '',\n",
      "             'best_checkpoint_metric_comp': 'higher',\n",
      "             'checkpoint_interval': 1000,\n",
      "             'continuous_eval_timeout': 3600,\n",
      "             'eval_tf_function': True,\n",
      "             'eval_tf_while_loop': False,\n",
      "             'loss_upper_bound': 1000000.0,\n",
      "             'max_to_keep': 5,\n",
      "             'optimizer_config': {'ema': None,\n",
      "                                  'learning_rate': {'polynomial': {'cycle': False,\n",
      "                                                                   'decay_steps': None,\n",
      "                                                                   'end_learning_rate': 0.0,\n",
      "                                                                   'initial_learning_rate': 3e-05,\n",
      "                                                                   'name': 'PolynomialDecay',\n",
      "                                                                   'power': 1.0},\n",
      "                                                    'type': 'polynomial'},\n",
      "                                  'optimizer': {'adamw': {'amsgrad': False,\n",
      "                                                          'beta_1': 0.9,\n",
      "                                                          'beta_2': 0.999,\n",
      "                                                          'clipnorm': None,\n",
      "                                                          'clipvalue': None,\n",
      "                                                          'epsilon': 1e-07,\n",
      "                                                          'exclude_from_weight_decay': ['LayerNorm',\n",
      "                                                                                        'layer_norm',\n",
      "                                                                                        'bias'],\n",
      "                                                          'global_clipnorm': None,\n",
      "                                                          'gradient_clip_norm': 1.0,\n",
      "                                                          'include_in_weight_decay': None,\n",
      "                                                          'name': 'AdamWeightDecay',\n",
      "                                                          'weight_decay_rate': 0.01},\n",
      "                                                'type': 'adamw'},\n",
      "                                  'warmup': {'polynomial': {'name': 'polynomial',\n",
      "                                                            'power': 1,\n",
      "                                                            'warmup_steps': None},\n",
      "                                             'type': 'polynomial'}},\n",
      "             'recovery_begin_steps': 0,\n",
      "             'recovery_max_trials': 0,\n",
      "             'steps_per_loop': 1000,\n",
      "             'summary_interval': 1000,\n",
      "             'train_steps': 0,\n",
      "             'train_tf_function': True,\n",
      "             'train_tf_while_loop': True,\n",
      "             'validation_interval': 1000,\n",
      "             'validation_steps': -1}}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "print(pp.pformat(params.as_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = copy.deepcopy(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the configuration for the GLUE MNLI matched experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_params = {\n",
    "    'task': {\n",
    "        'hub_module_url': 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4',\n",
    "        'train_data': {\n",
    "            'input_path': train_file,\n",
    "            'seq_length': 128,\n",
    "            'global_batch_size': 32\n",
    "        },\n",
    "        'validation_data': {\n",
    "            'input_path': eval_file,\n",
    "            'seq_length': 128,\n",
    "            'global_batch_size': 32\n",
    "        },\n",
    "        'model': {\n",
    "            'num_classes': 3\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'trainer': {\n",
    "        'train_steps': 36813,\n",
    "        'validation_steps': 307,\n",
    "        'validation_interval': 6135,\n",
    "        'checkpoint_interval': 3000,\n",
    "        'best_checkpoint_export_subdir': 'best_ckpt',\n",
    "        'best_checkpoint_eval_metric': 'cls_accuracy',\n",
    "        'best_checkpoint_metric_comp': 'higher',\n",
    "        'optimizer_config': {\n",
    "            'learning_rate': {\n",
    "                'polynomial': {\n",
    "                    'decay_steps': 36813\n",
    "                }\n",
    "            },\n",
    "            'warmup': {\n",
    "                'polynomial': {\n",
    "                    'warmup_steps': 3681\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'runtime': {\n",
    "        'num_gpus': 1,\n",
    "        'distribution_strategy': 'mirrored'\n",
    "    }\n",
    "}\n",
    "\n",
    "params.override(updated_params, is_strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type_changes': {'root.trainer.optimizer_config.learning_rate.polynomial.decay_steps': {'old_type': NoneType,\n",
       "   'new_type': int,\n",
       "   'old_value': None,\n",
       "   'new_value': 36813},\n",
       "  'root.trainer.optimizer_config.warmup.polynomial.warmup_steps': {'old_type': NoneType,\n",
       "   'new_type': int,\n",
       "   'old_value': None,\n",
       "   'new_value': 3681}},\n",
       " 'values_changed': {'root.task.model.num_classes': {'new_value': 3,\n",
       "   'old_value': 0},\n",
       "  'root.task.train_data.input_path': {'new_value': 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record',\n",
       "   'old_value': ''},\n",
       "  'root.task.validation_data.input_path': {'new_value': 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record',\n",
       "   'old_value': ''},\n",
       "  'root.task.hub_module_url': {'new_value': 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4',\n",
       "   'old_value': ''},\n",
       "  'root.trainer.checkpoint_interval': {'new_value': 3000, 'old_value': 1000},\n",
       "  'root.trainer.train_steps': {'new_value': 36813, 'old_value': 0},\n",
       "  'root.trainer.validation_steps': {'new_value': 307, 'old_value': -1},\n",
       "  'root.trainer.validation_interval': {'new_value': 6135, 'old_value': 1000},\n",
       "  'root.trainer.best_checkpoint_export_subdir': {'new_value': 'best_ckpt',\n",
       "   'old_value': ''},\n",
       "  'root.trainer.best_checkpoint_eval_metric': {'new_value': 'cls_accuracy',\n",
       "   'old_value': ''},\n",
       "  'root.runtime.num_gpus': {'new_value': 1, 'old_value': 0}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepDiff(default_params, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "distribution_strategy = distribute_utils.get_distribution_strategy(\n",
    "      distribution_strategy=params.runtime.distribution_strategy,\n",
    "      all_reduce_alg=params.runtime.all_reduce_alg,\n",
    "      num_gpus=params.runtime.num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "    task = task_factory.get_task(params.task, logging_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring or initializing model...\n",
      "restored model from /tmp/models/bert_mnli/ckpt-25540.\n",
      "restored from checkpoint: /tmp/models/bert_mnli/ckpt-25540\n",
      "train | step:  25540 | training until step 31675...\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,16,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/body/_1/bert_classifier/model/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_14/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Func/while/body/_1/output_control_node/_4833/_47]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,16,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/body/_1/bert_classifier/model/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_14/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_loop_fn_131206]\n\nFunction call stack:\nloop_fn -> loop_fn\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ec01a97b61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_and_eval'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       model_dir=model_dir)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/official/core/train_lib.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(distribution_strategy, task, mode, params, model_dir, run_post_eval, save_summary)\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m           \u001b[0meval_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m           eval_interval=params.trainer.validation_interval)\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/orbit/controller.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, train_steps, eval_steps, eval_interval)\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_at_completion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/orbit/controller.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps, checkpoint_at_completion)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;31m# Calculates steps to run for the next train loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_n_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/orbit/controller.py\u001b[0m in \u001b[0;36m_train_n_steps\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    408\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mnum_steps_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/orbit/standard_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_loop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,16,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/body/_1/bert_classifier/model/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_14/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Func/while/body/_1/output_control_node/_4833/_47]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,16,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/body/_1/bert_classifier/model/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_14/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_loop_fn_131206]\n\nFunction call stack:\nloop_fn -> loop_fn\n"
     ]
    }
   ],
   "source": [
    "train_lib.run_experiment(\n",
    "      distribution_strategy=distribution_strategy,\n",
    "      task=task,\n",
    "      mode='train_and_eval',\n",
    "      params=params,\n",
    "      model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m70",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m70"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
